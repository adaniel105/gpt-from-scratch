{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXfv8v/hCpJEGkA6FMZBIl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "id": "6Gkv1yfVKWor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058cc08e-8f78-4881-8f4c-aa3cc2e3437c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-20 23:25:55--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-08-20 23:25:55 (23.0 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "X-fWg7aYs6Ly"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of dataset in characters: {len(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G59FkgzZtKpd",
        "outputId": "bd89bc64-86f8-46af-cff3-379899843350"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1tz7RdotXxV",
        "outputId": "833a12fb-b38c-4060-ea74-bfd397267fb7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_sz = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_sz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSaueaAsubt6",
        "outputId": "99f54938-c215-4d67-a72b-7a448a4689c4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a simple tokenizer\n",
        "stoi = { ch:i for i,ch in enumerate(chars)}\n",
        "itos = { i: ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda c: [itos[i] for i in c]\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(''.join(decode(encode(\"hii there\"))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAtwrJ-Pvt06",
        "outputId": "e3797d89-5785-4d01-9252-5085e8b4bcf9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding entirety of input text with tokenizer\n",
        "import torch\n",
        "data = torch.tensor(encode(text), dtype= torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWQAaA0oyjYM",
        "outputId": "17c7d21b-2a60-4a4f-bad2-21f9e4e7f772"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#90/10 data split\n",
        "n = int(0.9*len(data))\n",
        "train = data[:n]\n",
        "val = data[n:]\n",
        "\n",
        "print(train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gYaLqdX3onG",
        "outputId": "b140b634-a83b-432e-e10f-8b7044ebfdfc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization of the autoregressive techniuque used by transformers for language modeling\n",
        "block_sz = 8\n",
        "x = train[:block_sz]\n",
        "y = train[1:block_sz + 1]\n",
        "for t in range(block_sz):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} the target: {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG-ZoDk53-aX",
        "outputId": "476d136e-d4a1-4ae2-8605-9446d6427d38"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(80)\n",
        "batch_sz = 4 #number of input sequences to be processed in parallel\n",
        "block_sz = 8 #maximum context length of predictions\n",
        "\n",
        "def get_batch(split):\n",
        "  #generate a small batch of data of inputs x and targets y\n",
        "  data = train if split == 'train' else val\n",
        "  ix = torch.randint(len(data) - block_sz, (batch_sz,))\n",
        "  x = torch.stack([data[i:i+block_sz] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_sz+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('-----')\n",
        "\n",
        "for b in range(batch_sz): #batch dimension\n",
        "  for t in range(block_sz): #time dimension\n",
        "    context = xb[b,:t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"when the input is {context.tolist()}, the output is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z116RYtz75sa",
        "outputId": "8052fcef-ddd9-4d7d-f7e9-971746de2f1d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[52, 42,  1, 42, 47, 42,  1, 58],\n",
            "        [39, 42, 50, 63,  1, 57, 54, 53],\n",
            "        [51,  1, 58, 53,  1, 39, 50, 50],\n",
            "        [63, 53, 59,  6,  1, 59, 52, 41]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[42,  1, 42, 47, 42,  1, 58, 56],\n",
            "        [42, 50, 63,  1, 57, 54, 53, 49],\n",
            "        [ 1, 58, 53,  1, 39, 50, 50, 11],\n",
            "        [53, 59,  6,  1, 59, 52, 41, 50]])\n",
            "-----\n",
            "when the input is [52], the output is 42\n",
            "when the input is [52, 42], the output is 1\n",
            "when the input is [52, 42, 1], the output is 42\n",
            "when the input is [52, 42, 1, 42], the output is 47\n",
            "when the input is [52, 42, 1, 42, 47], the output is 42\n",
            "when the input is [52, 42, 1, 42, 47, 42], the output is 1\n",
            "when the input is [52, 42, 1, 42, 47, 42, 1], the output is 58\n",
            "when the input is [52, 42, 1, 42, 47, 42, 1, 58], the output is 56\n",
            "when the input is [39], the output is 42\n",
            "when the input is [39, 42], the output is 50\n",
            "when the input is [39, 42, 50], the output is 63\n",
            "when the input is [39, 42, 50, 63], the output is 1\n",
            "when the input is [39, 42, 50, 63, 1], the output is 57\n",
            "when the input is [39, 42, 50, 63, 1, 57], the output is 54\n",
            "when the input is [39, 42, 50, 63, 1, 57, 54], the output is 53\n",
            "when the input is [39, 42, 50, 63, 1, 57, 54, 53], the output is 49\n",
            "when the input is [51], the output is 1\n",
            "when the input is [51, 1], the output is 58\n",
            "when the input is [51, 1, 58], the output is 53\n",
            "when the input is [51, 1, 58, 53], the output is 1\n",
            "when the input is [51, 1, 58, 53, 1], the output is 39\n",
            "when the input is [51, 1, 58, 53, 1, 39], the output is 50\n",
            "when the input is [51, 1, 58, 53, 1, 39, 50], the output is 50\n",
            "when the input is [51, 1, 58, 53, 1, 39, 50, 50], the output is 11\n",
            "when the input is [63], the output is 53\n",
            "when the input is [63, 53], the output is 59\n",
            "when the input is [63, 53, 59], the output is 6\n",
            "when the input is [63, 53, 59, 6], the output is 1\n",
            "when the input is [63, 53, 59, 6, 1], the output is 59\n",
            "when the input is [63, 53, 59, 6, 1, 59], the output is 52\n",
            "when the input is [63, 53, 59, 6, 1, 59, 52], the output is 41\n",
            "when the input is [63, 53, 59, 6, 1, 59, 52, 41], the output is 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FEEDING OUR PREPROCESSED TRAINING DATA INTO NEURAL NETWORKS"
      ],
      "metadata": {
        "id": "548bb9aiMYh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(80)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_sz):\n",
        "      super().__init__()\n",
        "      #each token directly reads off the logits for the next token in a lookup table\n",
        "      self.token_embedding_table = nn.Embedding(vocab_sz, vocab_sz)\n",
        "\n",
        "    def forward(self,idx,targets):\n",
        "      #both idx and tensor are 2-dimensional (B,T) tensor of integers\n",
        "      logits = self.token_embedding_table(idx) #(B, T, C)\n",
        "\n",
        "      #since pytorch expects a (B,C,T) tensor, we reshape the tensor using torch.view()\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T,C)\n",
        "      targets = targets.view(B*T) #combining our batch and time dimensions\n",
        "\n",
        "      loss = F.cross_entropy(logits, targets) #negative log-likehood loss fn\n",
        "      return logits, loss\n",
        "\n",
        "m = BigramLanguageModel(vocab_sz)\n",
        "logits, loss = m(xb, yb)\n",
        "\n",
        "print(logits)\n",
        "print(logits.shape)\n",
        "print(loss) #NOTE: ideal nll loss = -ln(1/vocab_sz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih2olNgIAeta",
        "outputId": "2e87475a-cb6f-4ef8-c71f-79d9ed5a9b6a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2811, -0.2446,  0.3116,  ...,  0.2522, -0.0340, -0.8544],\n",
            "        [-0.0927, -1.2656, -2.1652,  ..., -0.0186,  0.9552,  1.3387],\n",
            "        [-0.3464, -1.1768, -2.6356,  ...,  1.7470,  1.1502, -0.0674],\n",
            "        ...,\n",
            "        [ 1.0463, -0.3701,  1.5730,  ...,  0.1144,  1.5161,  1.6939],\n",
            "        [ 1.2811, -0.2446,  0.3116,  ...,  0.2522, -0.0340, -0.8544],\n",
            "        [ 0.9166, -0.5317, -0.2654,  ...,  0.3093, -0.0615, -0.7909]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([32, 65])\n",
            "tensor(4.7332, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}